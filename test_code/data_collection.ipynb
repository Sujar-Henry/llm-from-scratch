{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e46413",
   "metadata": {},
   "source": [
    "# Data Collection for LLM Training\n",
    "\n",
    "This notebook demonstrates how to collect and preprocess text data for training a language model. We'll use \"The Adventures of Sherlock Holmes\" from Project Gutenberg as our example dataset.\n",
    "\n",
    "## Steps covered:\n",
    "1. **Download** text data from Project Gutenberg\n",
    "2. **Load and inspect** the raw text\n",
    "3. **Tokenize** the text by splitting on punctuation and spaces\n",
    "4. **Clean** the tokens by removing empty strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa5a9b",
   "metadata": {},
   "source": [
    "## 1. Download Text Data\n",
    "\n",
    "We'll download \"The Adventures of Sherlock Holmes\" from Project Gutenberg, which provides free access to thousands of books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20abfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Check if we already have the file to avoid re-downloading\n",
    "if not os.path.exists(\"sherlock-holmes.txt\"):\n",
    "    # URL for \"The Adventures of Sherlock Holmes\" from Project Gutenberg\n",
    "    url = (\"https://www.gutenberg.org/files/1661/1661-0.txt\")\n",
    "    file_path = \"sherlock-holmes.txt\"\n",
    "    \n",
    "    # Download the file and save it locally\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "    print(\"âœ… Downloaded Sherlock Holmes text\")\n",
    "else:\n",
    "    print(\"ðŸ“„ File already exists, skipping download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire text file into memory\n",
    "with open(\"sherlock-holmes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# Check the size and preview the content\n",
    "print(\"Total number of characters:\", len(raw_text))\n",
    "print(\"\\nðŸ“– First 1000 characters:\")\n",
    "print(\"-\" * 50)\n",
    "print(raw_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc11a6d",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect the Text\n",
    "\n",
    "Now let's load the downloaded text file and see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba136e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test', ' ', 'for', ' ', 'Sherlock', ' ', 'Holmes.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example 1: Simple split on whitespace\n",
    "text = \"Test for Sherlock Holmes.\"\n",
    "\n",
    "# re.split with (\\s) captures the delimiter (whitespace) in the result\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(\"Splitting on whitespace (keeping delimiters):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e50c00",
   "metadata": {},
   "source": [
    "## 3. Text Tokenization\n",
    "\n",
    "Tokenization is the process of splitting text into smaller units (tokens) that can be processed by our language model. Let's start with some simple examples to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33405f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Split on punctuation AND whitespace\n",
    "# This captures commas, periods, and spaces as separate tokens\n",
    "result = re.split(r'([,.]|\\s)', text)\n",
    "\n",
    "print(\"Splitting on punctuation and whitespace:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5331564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test', 'for', 'Sherlock', 'Holmes', '.']\n"
     ]
    }
   ],
   "source": [
    "# Strip whitespace from each item and then filter out any empty strings.\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298103d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b39ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', ',', 'by', 'Arthur', 'Conan', 'Doyle', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea38ee0",
   "metadata": {},
   "source": [
    "## 4. Apply Tokenization to Full Text\n",
    "\n",
    "Now let's apply our tokenization strategy to the entire Sherlock Holmes text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675c8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126189\n",
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', ',', 'by', 'Arthur', 'Conan', 'Doyle', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', '.', 'gutenberg', '.', 'org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'Author', ':', 'Arthur', 'Conan', 'Doyle', 'Release', 'Date', ':', 'November', '29', ',', '2002', '[eBook', '#1661]', '[Most', 'recently', 'updated', ':', 'October', '10', ',', '2023]', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'an', 'anonymous', 'Project', 'Gutenberg', 'volunteer', 'and', 'Jose', 'Menendez', '***', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'ADVENTURES', 'OF', 'SHERLOCK', 'HOLMES', '***', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'by', 'Arthur', 'Conan', 'Doyle', 'Contents', 'I', '.', 'A', 'Scandal', 'in', 'Bohemia', 'II', '.', 'The', 'Red-Headed', 'League', 'III', '.', 'A', 'Case', 'of', 'Identity', 'IV', '.', 'The', 'Boscombe', 'Valley', 'Mystery', 'V', '.', 'The', 'Five', 'Orange', 'Pips', 'VI', '.', 'The', 'Man', 'with', 'the', 'Twisted', 'Lip', 'VII', '.', 'The', 'Adventure', 'of', 'the', 'Blue', 'Carbuncle', 'VIII', '.', 'The', 'Adventure', 'of', 'the', 'Speckled', 'Band', 'IX', '.', 'The', 'Adventure', 'of', 'the', 'Engineerâ€™s', 'Thumb', 'X', '.', 'The', 'Adventure', 'of', 'the', 'Noble', 'Bachelor', 'XI', '.', 'The', 'Adventure', 'of', 'the', 'Beryl', 'Coronet', 'XII', '.', 'The', 'Adventure', 'of', 'the', 'Copper', 'Beeches', 'I', '.', 'A', 'SCANDAL', 'IN', 'BOHEMIA', 'I', '.', 'To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_', 'the', '_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.', 'In', 'his', 'eyes', 'she', 'eclipses', 'and', 'predominates', 'the', 'whole', 'of', 'her', 'sex', '.', 'It', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler', '.', 'All', 'emotions', ',', 'and', 'that', 'one', 'particularly', ',', 'were', 'abhorrent', 'to', 'his', 'cold', ',', 'precise', 'but', 'admirably', 'balanced', 'mind', '.', 'He', 'was', ',', 'I', 'take', 'it', ',', 'the', 'most', 'perfect', 'reasoning', 'and', 'observing', 'machine', 'that', 'the', 'world', 'has', 'seen', ',', 'but', 'as', 'a', 'lover', 'he', 'would', 'have', 'placed', 'himself', 'in', 'a', 'false', 'position', '.', 'He', 'never', 'spoke', 'of', 'the', 'softer', 'passions', ',', 'save', 'with', 'a', 'gibe', 'and', 'a', 'sneer', '.', 'They', 'were', 'admirable', 'things', 'for', 'the', 'observerâ€”excellent', 'for', 'drawing', 'the', 'veil', 'from', 'menâ€™s', 'motives', 'and', 'actions', '.', 'But', 'for', 'the', 'trained', 'reasoner', 'to', 'admit', 'such', 'intrusions', 'into', 'his', 'own', 'delicate', 'and', 'finely', 'adjusted', 'temperament', 'was', 'to', 'introduce', 'a', 'distracting', 'factor', 'which', 'might', 'throw', 'a', 'doubt', 'upon', 'all', 'his', 'mental', 'results', '.', 'Grit', 'in', 'a', 'sensitive', 'instrument', ',', 'or', 'a', 'crack', 'in', 'one', 'of', 'his', 'own', 'high-power', 'lenses', ',', 'would', 'not', 'be', 'more', 'disturbing', 'than', 'a', 'strong', 'emotion', 'in', 'a', 'nature', 'such', 'as', 'his', '.', 'And', 'yet', 'there', 'was', 'but', 'one', 'woman', 'to', 'him', ',', 'and', 'that', 'woman', 'was', 'the', 'late', 'Irene', 'Adler', ',', 'of', 'dubious', 'and', 'questionable', 'memory', '.', 'I', 'had', 'seen', 'little', 'of', 'Holmes', 'lately', '.', 'My', 'marriage', 'had', 'drifted', 'us', 'away', 'from', 'each', 'other', '.', 'My', 'own', 'complete', 'happiness', ',', 'and', 'the', 'home-centred', 'interests', 'which', 'rise', 'up', 'around', 'the', 'man', 'who', 'first', 'finds', 'himself', 'master', 'of', 'his', 'own', 'establishment', ',', 'were', 'sufficient', 'to', 'absorb', 'all', 'my', 'attention', ',', 'while', 'Holmes', ',', 'who', 'loathed', 'every', 'form', 'of', 'society', 'with', 'his', 'whole', 'Bohemian', 'soul', ',', 'remained', 'in', 'our', 'lodgings', 'in', 'Baker', 'Street', ',', 'buried', 'among', 'his', 'old', 'books', ',', 'and', 'alternating', 'from', 'week', 'to', 'week', 'between', 'cocaine', 'and', 'ambition', ',', 'the', 'drowsiness', 'of', 'the', 'drug', ',', 'and', 'the', 'fierce', 'energy', 'of', 'his', 'own', 'keen', 'nature', '.', 'He', 'was', 'still', ',', 'as', 'ever', ',', 'deeply', 'attracted', 'by', 'the', 'study', 'of', 'crime', ',', 'and', 'occupied', 'his', 'immense', 'faculties', 'and', 'extraordinary', 'powers', 'of', 'observation', 'in', 'following', 'out', 'those', 'clues', ',', 'and', 'clearing', 'up', 'those', 'mysteries', 'which', 'had', 'been', 'abandoned', 'as', 'hopeless', 'by', 'the', 'official', 'police', '.', 'From', 'time', 'to', 'time', 'I', 'heard', 'some', 'vague', 'account', 'of', 'his', 'doings', ':', 'of', 'his', 'summons', 'to', 'Odessa', 'in', 'the', 'case', 'of', 'the', 'Trepoff', 'murder', ',', 'of', 'his', 'clearing', 'up', 'of', 'the', 'singular', 'tragedy', 'of', 'the', 'Atkinson', 'brothers', 'at', 'Trincomalee', ',', 'and', 'finally', 'of', 'the', 'mission', 'which', 'he', 'had', 'accomplished', 'so', 'delicately', 'and', 'successfully', 'for', 'the', 'reigning', 'family', 'of', 'Holland', '.', 'Beyond', 'these', 'signs', 'of', 'his', 'activity', ',', 'however', ',', 'which', 'I', 'merely', 'shared', 'with', 'all', 'the', 'readers', 'of', 'the', 'daily', 'press', ',', 'I', 'knew', 'little', 'of', 'my', 'former', 'friend', 'and', 'companion', '.', 'One', 'nightâ€”it', 'was', 'on', 'the', 'twentieth', 'of', 'March', ',', '1888â€”I', 'was', 'returning', 'from', 'a', 'journey', 'to', 'a', 'patient', '(', 'for', 'I', 'had', 'now', 'returned', 'to', 'civil', 'practice', ')', ',', 'when', 'my', 'way', 'led', 'me', 'through', 'Baker', 'Street', '.', 'As', 'I', 'passed', 'the', 'well-remembered', 'door', ',', 'which', 'must', 'always', 'be', 'associated', 'in', 'my', 'mind', 'with', 'my', 'wooing', ',', 'and', 'with', 'the', 'dark', 'incidents', 'of', 'the', 'Study', 'in', 'Scarlet', ',', 'I', 'was', 'seized', 'with', 'a', 'keen', 'desire', 'to', 'see', 'Holmes', 'again', ',', 'and', 'to', 'know', 'how', 'he', 'was', 'employing', 'his', 'extraordinary', 'powers', '.', 'His', 'rooms', 'were', 'brilliantly', 'lit', ',', 'and', ',', 'even', 'as', 'I', 'looked', 'up', ',', 'I', 'saw', 'his', 'tall', ',', 'spare', 'figure', 'pass', 'twice', 'in', 'a', 'dark', 'silhouette', 'against', 'the', 'blind', '.', 'He', 'was', 'pacing', 'the', 'room', 'swiftly', ',', 'eagerly', ',', 'with', 'his', 'head', 'sunk', 'upon', 'his', 'chest', 'and', 'his', 'hands', 'clasped', 'behind', 'him', '.', 'To', 'me', ',', 'who', 'knew', 'his', 'every', 'mood', 'and', 'habit', ',', 'his', 'attitude', 'and', 'manner', 'told', 'their', 'own', 'story', '.', 'He', 'was', 'at', 'work', 'again', '.', 'He', 'had', 'risen', 'out', 'of', 'his', 'drug-created', 'dreams', 'and', 'was', 'hot', 'upon', 'the', 'scent', 'of', 'some', 'new', 'problem', '.', 'I', 'rang', 'the', 'bell', 'and', 'was', 'shown', 'up', 'to', 'the', 'chamber', 'which', 'had', 'formerly', 'been', 'in', 'part', 'my', 'own', '.', 'His', 'manner', 'was', 'not', 'effusive', '.', 'It', 'seldom', 'was', ';', 'but', 'he', 'was', 'glad', ',', 'I', 'think', ',', 'to', 'see', 'me', '.', 'With', 'hardly', 'a', 'word', 'spoken', ',', 'but', 'with', 'a', 'kindly', 'eye', ',', 'he', 'waved', 'me', 'to', 'an', 'armchair', ',', 'threw', 'across']\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))\n",
    "print(preprocessed[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a14a08",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **What we accomplished:**\n",
    "- Downloaded a classic text from Project Gutenberg\n",
    "- Loaded and inspected the raw text data\n",
    "- Learned different tokenization approaches using regex\n",
    "- Applied comprehensive tokenization to split text into meaningful tokens\n",
    "- Cleaned the data by removing empty tokens\n",
    "\n",
    "ðŸŽ¯ **Next steps for LLM training:**\n",
    "- Create a vocabulary from these tokens\n",
    "- Convert tokens to numerical IDs\n",
    "- Organize data into training batches\n",
    "- Feed to a neural network for language model training\n",
    "\n",
    "This preprocessed token list is now ready to be used as training data for a language model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sujar-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
